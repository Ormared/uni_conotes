>В основі методу лежить **принцип оптимальності**: “Яким би не був стан системи в результаті деякого числа кроків, на найближчому кроці треба вибирати керування так, щоб воно в сукупності з оптимальним керуванням на всіх наступних кроках приводило до оптимального виграшу на всіх наступних кроках включаючи даний”

Згідно з принципом оптимальності на кожному кроці $X_k$ керування
треба вибирати з врахуванням його впливу на наступні кроки. Але є один
крок, останній, який можна для довільного стану $S_{n-1}$ планувати ***локально-
оптимально***, виходячи лише з інтересів цього кроку

Функція умовного максимуму цільової функції на n-му кроці: $$Z_n^*(s_{n-1}) = max f_n(S_{n-1}, X_n)$$(5)

Таким чином, розв’язуючи одновимірну задачу локальної оптимізації за рівнянням (5), знайдемо для всіх можливих станів дві функції: $$Z_n^*(s_{n-1}) \space і \space X_n^*(s_{n-1})$$
Остання функція є умовно-оптимальним керуванням на n-му кроці 

**Рівнняння Беллмана**
$$
Z_k^*(s_{k-1}) = max \{f_k(s_{k-1}, X_k) + Z_{k+1}^*(s_k)\}
$$

Ці рекурентні співвідношення дозволяють знайти попереднє оптимальне значення цільової функції $Z_k^*(s_{k-1})$, якщо відомі наступні $f_k(s_{k-1}, X_k)$.

Ланцюжок розв'язання задачі виглядає наступним чином (див [[Постановка задачі динамічного програмування]])
![[Pasted image 20240601172438.png]]